{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66280656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst(0 Experience Required)</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Peroptyx</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Gurugram, India</td>\n",
       "      <td>Birlasoft</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst CX</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...</td>\n",
       "      <td>IDFC FIRST Bharat</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Gurugram(Sector 25 Gurgaon +1)</td>\n",
       "      <td>Xyle</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Delhi / NCR, New Delhi</td>\n",
       "      <td>CMS Computers</td>\n",
       "      <td>9-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Aster DM Healthcare</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Fleetx</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NIIT is Urgently hiring Data Analyst(Gurgaon)</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>NIIT</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Delhi / NCR, Mumbai, Bengaluru</td>\n",
       "      <td>Sava Healthcare</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title  \\\n",
       "0            Data Analyst(0 Experience Required)   \n",
       "1                                   Data Analyst   \n",
       "2                                Data Analyst CX   \n",
       "3                                   Data Analyst   \n",
       "4                                   Data Analyst   \n",
       "5                                   Data Analyst   \n",
       "6                                   Data Analyst   \n",
       "7                                   Data Analyst   \n",
       "8  NIIT is Urgently hiring Data Analyst(Gurgaon)   \n",
       "9                                   Data Analyst   \n",
       "\n",
       "                                            Location         Company_name  \\\n",
       "0                                             Remote             Peroptyx   \n",
       "1                           Hybrid - Gurugram, India            Birlasoft   \n",
       "2  Kolkata, Mumbai, New Delhi, Hyderabad, Pune, C...    IDFC FIRST Bharat   \n",
       "3                                           Gurugram                Wipro   \n",
       "4                     Gurugram(Sector 25 Gurgaon +1)                 Xyle   \n",
       "5                             Delhi / NCR, New Delhi        CMS Computers   \n",
       "6                                           Gurugram  Aster DM Healthcare   \n",
       "7                                           Gurugram               Fleetx   \n",
       "8                                           Gurugram                 NIIT   \n",
       "9                     Delhi / NCR, Mumbai, Bengaluru      Sava Healthcare   \n",
       "\n",
       "  Experience  \n",
       "0    0-5 Yrs  \n",
       "1    4-6 Yrs  \n",
       "2   5-10 Yrs  \n",
       "3    2-4 Yrs  \n",
       "4    0-1 Yrs  \n",
       "5   9-12 Yrs  \n",
       "6    4-8 Yrs  \n",
       "7    1-2 Yrs  \n",
       "8   5-10 Yrs  \n",
       "9    0-5 Yrs  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')\n",
    "\n",
    "location = driver.find_element(By.XPATH, \"//input[@placeholder='Enter location']\")\n",
    "location.send_keys('Delhi/NCR')\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "salary_filter = driver.find_element(By.XPATH, '/html/body/div/div/main/div[1]/div[2]/div[2]/div/div[1]/div/div[1]')\n",
    "salary_filter.click()\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a')[:10]\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH, '//span[@class=\"locWdth\"]')[:10]\n",
    "for i in location_tags:\n",
    "    job_location.append(i.text)\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH, '//div[@class=\" row2\"]/span/a[1]')[:10]\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH, '//span[@class=\"expwdth\"]')[:10]\n",
    "for i in experience_tags:\n",
    "    experience_required.append(i.text)\n",
    "\n",
    "\n",
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Title': job_title,\n",
    "    'Location': job_location,\n",
    "    'Company_name': company_name,\n",
    "    'Experience': experience_required\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac9c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ce3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME, \"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')\n",
    "\n",
    "location = driver.find_element(By.XPATH, \"//input[@placeholder='Enter location']\")\n",
    "location.send_keys('Banglore')\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "salary_filter = driver.find_element(By.XPATH, '/html/body/div/div/main/div[1]/div[2]/div[2]/div/div[1]/div/div[1]')\n",
    "salary_filter.click()\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div/a')[:10]\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH, '//span[@class=\"locWdth\"]')[:10]\n",
    "for i in location_tags:\n",
    "    job_location.append(i.text)\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH, '//div[@class=\" row2\"]/span/a[1]')[:10]\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH, '//span[@class=\"expwdth\"]')[:10]\n",
    "for i in experience_tags:\n",
    "    experience_required.append(i.text)\n",
    "\n",
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Title': job_title,\n",
    "    'Location': job_location,\n",
    "    'Company_name': company_name,\n",
    "    'Experience': experience_required\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525bbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb03866",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")\n",
    "\n",
    "ratings = []\n",
    "review_summaries = []\n",
    "full_reviews = []\n",
    "\n",
    "def scroll_to_element(driver, element):\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "\n",
    "while len(ratings) < 100:\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"_1AtVbE\"]')))\n",
    "    \n",
    "    rating_tags = driver.find_elements(By.XPATH, '/html/body/div/div/div[3]/div/div[1]/div[2]/div[3]/div/div/div/div[1]/div')\n",
    "    for tag in rating_tags:\n",
    "        ratings.append(tag.text)\n",
    "        if len(ratings) >= 100:\n",
    "            break\n",
    "    \n",
    "    summary_tags = driver.find_elements(By.XPATH, '/html/body/div/div/div[3]/div/div[1]/div[2]/div[3]/div/div/div/div[1]/p')\n",
    "    for tag in summary_tags:\n",
    "        review_summaries.append(tag.text)\n",
    "        if len(review_summaries) >= 100:\n",
    "            break\n",
    "\n",
    "    full_review_tags = driver.find_elements(By.XPATH, '/html/body/div/div/div[3]/div/div[1]/div[2]/div[3]/div/div/div/div[2]/div')\n",
    "    for tag in full_review_tags:\n",
    "        full_reviews.append(tag.text)\n",
    "        if len(full_reviews) >= 100:\n",
    "            break\n",
    "\n",
    "    if len(ratings) < 100:\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//a[contains(@class, \"_1LKTO3\") and contains(text(), \"Next\")]')))\n",
    "            scroll_to_element(driver, next_button)\n",
    "            next_button.click()\n",
    "            time.sleep(3)  # Wait for the next page to load\n",
    "        except Exception as e:\n",
    "            print(\"Error locating next button:\", e)\n",
    "            break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "ratings = ratings[:100]\n",
    "review_summaries = review_summaries[:100]\n",
    "full_reviews = full_reviews[:100]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Rating': ratings,\n",
    "    'Review Summary': review_summaries,\n",
    "    'Full Review': full_reviews\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8219291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aea0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d781daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "search_input = driver.find_element(By.CLASS_NAME, \"Pke_EE\")\n",
    "search_input.send_keys('sneakers')\n",
    "\n",
    "search_button = driver.find_element(By.CLASS_NAME, \"_2iLD__\")\n",
    "search_button.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "brand = []\n",
    "product_description = []\n",
    "price = []\n",
    "\n",
    "while len(brand) > 100:\n",
    "    product_tags = driver.find_elements(By.XPATH, '/html/body/div/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/div')\n",
    "    for product in product_tags:\n",
    "        brand_tag = product.find_element(By.XPATH, '/html/body/div/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/div/div/div[2]')\n",
    "        brand.append(brand_tag.text)\n",
    "        \n",
    "        product_description_tag = product.find_element(By.XPATH, '/html/body/div/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/div/div/a[1]')\n",
    "        product_description.append(product_description_tag.text)\n",
    "        \n",
    "        price_tag = product.find_element(By.XPATH, '/html/body/div/div/div[3]/div[1]/div[2]/div[2]/div/div[1]/div/div/a[2]/div')\n",
    "        price.append(price_tag.text)\n",
    "    \n",
    "\n",
    "    next_page = driver.find_element(By.XPATH, '/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[2]')\n",
    "    next_page.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(len(brand), len(product_description), len(price))\n",
    "\n",
    "df = pd.DataFrame({'Brand': brand, 'Product Description': product_description, 'Price': price})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fffcd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044aa6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "search_input = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "search_input.send_keys('Laptop')\n",
    "\n",
    "# Find and click the search button\n",
    "search_button = driver.find_element(By.ID, \"nav-search-submit-button\")\n",
    "search_button.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "cpu_filter = driver.find_element(By.XPATH, '//span[text()=\"Intel Core i7\"]/ancestor::li')\n",
    "cpu_filter.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Lists to store the laptop details\n",
    "title = []\n",
    "ratings = []\n",
    "price = []\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]')[:10]\n",
    "for i in title_tags:\n",
    "    title.append(i.text)\n",
    "\n",
    "ratings_tags = driver.find_elements(By.XPATH, '//span[@class=\"a-icon-alt\"]')[:10]\n",
    "for i in ratings_tags:\n",
    "    ratings.append(i.text)\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')[:10]\n",
    "for i in price_tags:\n",
    "    price.append(i.text)\n",
    "\n",
    "print(len(title), len(ratings), len(price))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Title': title,\n",
    "    'Ratings': ratings,\n",
    "    'Price': price\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d4d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27723c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162de58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "\n",
    "top_quotes = driver.find_element(By.LINK_TEXT, \"TOP QUOTES\")\n",
    "top_quotes.click()\n",
    "\n",
    "\n",
    "quotes = []\n",
    "authors = []\n",
    "types = []\n",
    "\n",
    "while len(quotes) < 1000:\n",
    "    quote_tags = driver.find_elements(By.XPATH, '//div[@class=\"title\"]')\n",
    "    author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "    type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]')\n",
    "    for i in range(len(quote_tags)):\n",
    "        quotes.append(quote_tags[i].text)\n",
    "        authors.append(author_tags[i].text)\n",
    "        types.append(type_tags[i].text)\n",
    "    \n",
    "try:\n",
    "        next_button = driver.find_element(By.LINK_TEXT, \"Next â†’\")\n",
    "        next_button.click()\n",
    "        time.sleep(5)  # wait for the page to load\n",
    "except:\n",
    "        break  \n",
    "\n",
    "\n",
    "print(len(quotes), len(authors), len(types))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Quote': quotes,\n",
    "    'Author': authors,\n",
    "    'Type': types\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c236f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.jagranjosh.com/general-knowledge/list-ofall-prime-ministers-of-india-1473165149-1\")\n",
    "\n",
    "pm_names = []\n",
    "pm_born_dead = []\n",
    "pm_term_of_office = []\n",
    "pm_remarks = []\n",
    "\n",
    "pm_rows = driver.find_elements(By.XPATH, '//*[@id=\"itemdiv\"]/div[4]/div[8]/div/table/tbody')\n",
    "for row in pm_rows:\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    if len(cols) >= 4:\n",
    "        pm_names.append(cols[0].text)\n",
    "        pm_born_dead.append(cols[1].text)\n",
    "        pm_term_of_office.append(cols[2].text)\n",
    "        pm_remarks.append(cols[3].text)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Name': pm_names,\n",
    "    'Born-Dead': pm_born_dead,\n",
    "    'Term of Office': pm_term_of_office,\n",
    "    'Remarks': pm_remarks\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a96e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the Motor1 website\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "\n",
    "search_input = driver.find_element(By.NAME, \"q\")\n",
    "search_input.send_keys(\"50 most expensive cars\")\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    "article_link = driver.find_element(By.XPATH, '/html/body/div[9]/div[9]/div/div[1]/div/div/div[1]/div')\n",
    "article_link.click()\n",
    "\n",
    "\n",
    "\n",
    "car_names = []\n",
    "car_prices = []\n",
    "\n",
    "car_list = driver.find_elements(By.XPATH, '//*[@id=\"article_box\"]/div[1]/div[2]/div[2]/h3[1]')\n",
    "for car in car_list:\n",
    "    car_name = car.find_element(By.XPATH, '//div[@class=\"subheader\"]').text\n",
    "    car_price = car.find_element(By.XPATH, '//*[@id=\"article_box\"]/div[1]/div[2]/div[2]/p[4]/strong').text\n",
    "    car_names.append(car_name)\n",
    "    car_prices.append(car_price)\n",
    "\n",
    "print(len(car_names), len(car_prices))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Car Name': car_names,\n",
    "    'Price': car_prices\n",
    "})\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
